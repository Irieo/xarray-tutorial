{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a4abb99-d3c8-492c-a748-19be43d56fd1",
   "metadata": {},
   "source": [
    "<img src=\"../images/dask_horizontal.svg\" align=\"left\" width=\"30%\">\n",
    "<img src=\"../images/dataset-diagram-logo.png\" align=\"right\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d3aa3c-d623-4dc1-8361-e623b4ba0014",
   "metadata": {},
   "source": [
    "# Dask and Xarray\n",
    "\n",
    "\n",
    "This notebook demonstrates one of xarray's most powerful features: the ability to wrap dask arrays and allow users to seamlessly execute analysis code in parallel.\n",
    "\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Learn that xarray DataArrays and Datasets are \"dask collections\" i.e. you can execute top-level dask functions such as dask.visualize(xarray_object)\n",
    "- Learn that all xarray built-in operations can transparently use dask\n",
    "- Learn that xarray provides tools to easily parallelize custom functions across blocks of dask-backed xarray objects.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "\n",
    "| Concepts | Importance | Notes |\n",
    "| --- | --- | --- |\n",
    "| Familiarity with Dask Array | Necessary | |\n",
    "| Familiarity with xarray | Necessary | |\n",
    "\n",
    "- **Time to learn**: *15-20 minutes*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c1bc78-6d5e-4407-a1ef-a7e662e3e389",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First let's set up a `LocalCluster` using `dask.distributed`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbb8d31-b3ce-4634-a771-569b31b77c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.array as da\n",
    "import xarray as xr\n",
    "from dask.distributed import Client, LocalCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc56bf9-3122-484c-9cd9-f6b858c3c1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba4b6f6-f224-425e-b9fc-2390bf5a0232",
   "metadata": {},
   "source": [
    "## Reading data with Dask and Xarray\n",
    "\n",
    "Recall that a dask's array consists of many chunked arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e1b222-737c-4181-8031-b02317c6e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "darr = da.ones((2000, 300), chunks=(200, 50))\n",
    "darr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371f8e08-84ec-4af3-8ada-f68051149ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "darr.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef570f8-959a-4249-8c9a-28abd7e48e1a",
   "metadata": {},
   "source": [
    "To read data as dask arrays with xarray, we need to specify the `chunks` argument to `open_dataset()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd72d69d-32ec-4a76-bf06-58bc3b5a52d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\n",
    "    \"data/tos_Omon_CESM2_historical_r11i1p1f1_gr_200001-201412.nc\", engine=\"netcdf4\", chunks={}\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28bea74-8593-4053-ba51-7e2c6b34bfbc",
   "metadata": {},
   "source": [
    "Passing `chunks={}` to `open_dataset()` works, but since we didn't tell dask how to split up (or chunk) the array, Dask will create a single chunk for our array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2398993f-424e-4e2d-ade4-d790091db331",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\n",
    "    \"data/tos_Omon_CESM2_historical_r11i1p1f1_gr_200001-201412.nc\",\n",
    "    engine=\"netcdf4\",\n",
    "    chunks={\"time\": 90, \"lat\": 180, \"lon\": 360},\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a58b22-6af7-423b-ae7c-e951c2a5f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.tos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91daa092-05b5-4a96-a0d5-e6bfef3a2f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.tos.chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc2d903-5cae-436e-b1bb-886d48d15ae0",
   "metadata": {},
   "source": [
    "## Xarray data structures are first-class dask collections\n",
    "\n",
    "This means you can call the following functions \n",
    "\n",
    "- `dask.visualize(...)`\n",
    "- `dask.compute(...)`\n",
    "- `dask.persist(...)`\n",
    "\n",
    "on both xarray DataArrays and Datasets backed by dask-arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22ca274-17a7-41d6-a123-f86838851a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.visualize(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc861a0e-aa87-4ac3-be04-d9e3be3beed9",
   "metadata": {},
   "source": [
    "## Parallel and Lazy computation using `dask.array` with xarray\n",
    "\n",
    "\n",
    "Xarray seamlessly wraps dask so all computation is deferred until explicitly requested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0c1351-b666-4b59-b672-345a0ec90404",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = ds.tos.mean(['lat', 'lon']).dot(ds.tos.T)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2444bb09-cbab-4e6a-a374-ad19a936c831",
   "metadata": {},
   "source": [
    "As you can see, `z` contains a dask array. This is true for all xarray built-in operations including subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213eabbc-9d1d-4a35-9ac5-7ced8f88ca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.isel(lat=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feada15-6f9a-4091-9ab7-8d2ad3b237a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.visualize(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6077847d-09cb-481c-85d4-2bd023f9bfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "z.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5996ff04-3ff3-482a-8a01-027d0ba6e35d",
   "metadata": {},
   "source": [
    "## Reading multiple datasets with `open_mfdataset`\n",
    "\n",
    "Xarray provides a built-in function `xr.open_mfdataset()` for opening multiple files as a single dataset. This makes it easy to work with data from multiple files as one logical dataset. \n",
    "\n",
    "For demonstration purposes, let's revisit our example in [Dask Delayed Notebook](./08-dask-delayed.ipynb). In this example, we loop over a list of files (for four ensemble members), and we compute the anomaly for each ensemble member as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f839be00-17fa-41ce-a397-3c9300c7f60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "data_dir = pathlib.Path(\"data/\")\n",
    "files = sorted(data_dir.glob(\"tos_Omon_CESM2*\"))\n",
    "\n",
    "results = {}\n",
    "for file in files:\n",
    "\n",
    "    # Read in file\n",
    "    ds = dask.delayed(xr.open_dataset)(file, engine='netcdf4')\n",
    "\n",
    "    # Compute anomaly\n",
    "    gb = ds.tos.groupby('time.month')\n",
    "    tos_anom = gb - gb.mean(dim='time')\n",
    "\n",
    "    # Save the computed anomaly and record the name of the ensemble member\n",
    "    results[file.stem.split('_')[-3]] = tos_anom\n",
    "\n",
    "\n",
    "# Compute the results\n",
    "# dask.compute() returns a tuple here with a single item. So, ensure to grab this one item by using the 0 index\n",
    "computed_results = dask.compute(results)[0]\n",
    "# Combine the results in our dataarray by concatenating the results across a new dimension `ensemble_member`\n",
    "dset_anom = xr.concat(list(computed_results.values()), dim='ensemble_member')\n",
    "dset_anom['ensemble_member'] = list(computed_results.keys())\n",
    "dset_anom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bba85d-dd79-4ee0-9915-5b7f222da9d3",
   "metadata": {},
   "source": [
    "Instead of explicitly looping over the list of files to construct xarray datasets, we can pass the list of files to [`xr.open_mfdataset()`](https://xarray.pydata.org/en/stable/generated/xarray.open_mfdataset.html#xarray.open_mfdataset) and xarray will construct a single dataset for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d174e32-60b2-44ba-a63a-ed7ff04141df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = xr.open_mfdataset(\n",
    "    sorted(files),\n",
    "    concat_dim='ensemble_member',\n",
    "    combine=\"nested\",\n",
    "    parallel=True,\n",
    "    data_vars=['tos'],\n",
    "    engine=\"netcdf4\",\n",
    "    chunks={'time': 90},\n",
    ")\n",
    "# Add coordinate labels for the newly created `ensemble_member` dimension\n",
    "dset[\"ensemble_member\"] = ['r11i1p1f1', 'r7i1p1f1', 'r8i1p1f1', 'r9i1p1f1']\n",
    "dset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc1e7ee-5d02-4fe6-b794-15253f2cfb8e",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\"></p>\n",
    "    <ul>\n",
    "    <li>By default, open_mfdataset() will chunk each netCDF file into a single Dask array; supply the chunks argument to control the size of the resulting Dask arrays.</li>\n",
    "    <li>In more complex cases, you can open each file individually using open_dataset(..., chunks={...}) and merge the results into a single dataset.</li>\n",
    "        <li>Passing the keyword argument parallel=True to open_mfdataset() will speed up the reading of large multi-file datasets by executing those read tasks in parallel using dask.delayed.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1d3b7e-ba3c-45dd-ba70-1cc8f15af811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute anomaly\n",
    "gb = dset.tos.groupby('time.month')\n",
    "tos_anom = gb - gb.mean(dim='time')\n",
    "tos_anom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d1f67c-a7d6-410b-b645-ff32ad4d6458",
   "metadata": {},
   "outputs": [],
   "source": [
    "tos_anom.sel(lon=310, lat=50, method='nearest').plot(col='ensemble_member', col_wrap=2, size=4);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408fecf6-864e-4b0e-9699-edbabdb0adc2",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-warning\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\"></p>\n",
    "    Note that using plotting functionality will automatically trigger computation of required results.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e7c78f-1a01-406f-ad96-6d979802266e",
   "metadata": {},
   "source": [
    "So, with xarray's `open_mfdataset()`, the following code\n",
    "\n",
    "```python\n",
    "results = {}\n",
    "for file in files:\n",
    "\n",
    "    # Read in file\n",
    "    ds = dask.delayed(xr.open_dataset)(file, engine='netcdf4')\n",
    "\n",
    "    # Compute anomaly\n",
    "    gb = ds.tos.groupby('time.month')\n",
    "    tos_anom = gb - gb.mean(dim='time')\n",
    "\n",
    "    # Save the computed anomaly and record the name of the ensemble member\n",
    "    results[file.stem.split('_')[-3]] = tos_anom\n",
    "\n",
    "\n",
    "# Compute the results\n",
    "# dask.compute() returns a tuple here with a single item. So, ensure to grab this one item by using the 0 index\n",
    "computed_results = dask.compute(results)[0]\n",
    "# Combine the results in our dataarray by concatenating the results across a new dimension `ensemble_member`\n",
    "dset_anom = xr.concat(list(computed_results.values()), dim='ensemble_member')\n",
    "dset_anom['ensemble_member'] = list(computed_results.keys())\n",
    "```\n",
    "\n",
    "becomes \n",
    "\n",
    "\n",
    "```python\n",
    "dset = xr.open_mfdataset(sorted(files), concat_dim='ensemble_member', \n",
    "                         combine=\"nested\", parallel=True, data_vars=['tos'],\n",
    "                         engine=\"netcdf4\", chunks={'time': 90})\n",
    "# Add coordinate labels for the newly created `ensemble_member` dimension\n",
    "dset[\"ensemble_member\"] = ['r11i1p1f1', 'r7i1p1f1', 'r8i1p1f1', 'r9i1p1f1'] \n",
    "# Compute anomaly\n",
    "gb = dset.tos.groupby('time.month')\n",
    "tos_anom = gb - gb.mean(dim='time')\n",
    "```\n",
    "\n",
    "This latter version is cleaner and easier to maintain than the version with loops. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f3f0f5-969c-4013-be74-f8a87ae6b491",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa208cf-a2da-4bc8-b8d0-90ad2f2309fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark --time --python --updated --iversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bc93c6-d1d1-4bc1-9fec-197fade60206",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac98098-0ea2-4b85-b04f-0ae58a9c9f4b",
   "metadata": {},
   "source": [
    "## Learn More\n",
    "\n",
    "Visit the [Parallel computing with Dask documentation](https://xarray.pydata.org/en/stable/user-guide/dask.html), and the [dask array best practices](https://docs.dask.org/en/latest/array-best-practices.html) which provides advice on using `dask.array` well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cda9549-2a22-4b72-b40d-5fb899482e3c",
   "metadata": {},
   "source": [
    "## Resources and references\n",
    "\n",
    "* Reference\n",
    "    *  [Dask Docs](https://dask.org/)\n",
    "    *  [Dask Blog](https://blog.dask.org/)\n",
    "    *  [Xarray Docs](https://xarray.pydata.org/)\n",
    "  \n",
    "*  Ask for help\n",
    "    *   [`dask`](http://stackoverflow.com/questions/tagged/dask) tag on Stack Overflow, for usage questions\n",
    "    *   [github discussions (dask):](https://github.com/dask/dask/discussions) for general, non-bug, discussion, and usage questions\n",
    "    *   [github issues (dask): ](https://github.com/dask/dask/issues/new) for bug reports and feature requests\n",
    "     *   [github discussions (xarray): ](https://github.com/pydata/xarray/discussions) for general, non-bug, discussion, and usage questions\n",
    "    *   [github issues (xarray): ](https://github.com/pydata/xarray/issues/new) for bug reports and feature requests\n",
    "    \n",
    "* Pieces of this notebook are adapted from the following sources\n",
    "  * https://github.com/xarray-contrib/xarray-tutorial/blob/master/scipy-tutorial/06_xarray_and_dask.ipynb\n",
    "  \n",
    "  \n",
    "  \n",
    " <div class=\"admonition alert alert-success\">\n",
    "    <p class=\"title\" style=\"font-weight:bold\">Previous: <a href=\"./08-dask-delayed.ipynb\">Dask Delayed</a></p>\n",
    "     <p class=\"title\" style=\"font-weight:bold\">Next: <a href=\"./10-dask-and-xarray.ipynb\">Dask and Xarray</a></p>\n",
    "    \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
