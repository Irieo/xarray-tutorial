{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7df3a8f0-0ef1-4e50-9d41-afb98c875426",
   "metadata": {},
   "source": [
    "<img src=\"../images/dask_horizontal.svg\" align=\"right\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4b7e4f-b66d-49c5-8ddd-7c460742878c",
   "metadata": {},
   "source": [
    "# Parallelize code with `dask.delayed`\n",
    "\n",
    "\n",
    "\n",
    "In this section we parallelize simple for-loop style code with Dask and `dask.delayed`. Often, this is the only function that you will need to convert functions for use with Dask.\n",
    "\n",
    "This is a simple way to use `dask` to parallelize existing codebases or build [complex systems](https://blog.dask.org/2018/02/09/credit-models-with-dask).  This will also help us to develop an understanding for later sections.\n",
    "\n",
    "\n",
    "## Learning Objectives \n",
    "\n",
    "- Deploy a local Dask Distributed Cluster and access the diagnostics dashboard\n",
    "- Work with `dask.delayed` to parallelize custom functions/workloads\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "\n",
    "| Concepts | Importance | Notes |\n",
    "| --- | --- | --- |\n",
    "| Familiarity with Python | Necessary | |\n",
    "| Familiarity with xarray | Helpful | |\n",
    "\n",
    "\n",
    "- **Time to learn**: *25-35 minutes*\n",
    "\n",
    "\n",
    "\n",
    "## Deploy a local Dask Distributed Cluster\n",
    "\n",
    "As we'll see in the [distributed scheduler notebook](11-dask-distributed.ipynb), Dask has several ways of executing code in parallel. We'll use the distributed scheduler by creating a `dask.distributed.LocalCluster` and then passing that to the `dask.distributed.Client`. For now, this will provide us with some nice diagnostics. We'll talk about schedulers in depth later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ba56ab-d58e-4698-ae08-5d3ef99cfdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc91335-2714-45ca-8787-53467515315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cc7c13-0b12-4ea8-b7da-a3ad0f18a6c9",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "\n",
    "- A cluster is a set of \"workers\". In the `LocalCluster` case, these workers are all on a single machine\n",
    "- A client allows us to connect our jupyter notebook or script to the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cc7d17-d608-4411-a71b-95209db1f376",
   "metadata": {},
   "source": [
    "You may want to look at the keyword arguments available on `LocalCluster` to understand the options available to you on handling the mixture of threads and processes, etc... by un-commenting the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb82cab-3772-4c3b-8e71-68305fd82aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LocalCluster?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e429aa5-1930-47f3-8662-2a5110ed2f92",
   "metadata": {},
   "source": [
    "## Basics\n",
    "\n",
    "First let's make some toy functions, `square`, `add`, and `square_root` that sleep for a while to simulate work. We'll then time running these functions normally.\n",
    "\n",
    "In the next section we'll parallelize this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a89f20-ef69-443c-83a8-0a8b17857dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47455322-fa5e-4e64-8d54-b84780fd32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    time.sleep(1)\n",
    "    return x ** 2\n",
    "\n",
    "\n",
    "def add(x, y):\n",
    "    time.sleep(1)\n",
    "    return x + y\n",
    "\n",
    "\n",
    "def square_root(x):\n",
    "    time.sleep(1)\n",
    "    return x ** (1 / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83076b9-01cc-4aab-b53d-ae728ec8e2a1",
   "metadata": {},
   "source": [
    "We time the execution of this normal code using the `%%time` magic, which is a special function of the Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de312450-fd53-4973-88d9-44012ddb8b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "x = square(3)\n",
    "y = square(4)\n",
    "z = add(x, y)\n",
    "r = square_root(z)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b8abd1-866c-40e6-897c-48f7b479c8fa",
   "metadata": {},
   "source": [
    "This takes `~4 seconds` to run because we call each function sequentially, one after the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d0788e-6c3c-462b-98ef-d7ddf82d7188",
   "metadata": {},
   "source": [
    "Those two `square` calls *could* be called in parallel, because they are totally independent of one-another.\n",
    "\n",
    "We'll transform the `square`, `add`, and `square_root` functions using the `dask.delayed` function. When we call the delayed version by passing the arguments, exactly as before, the original function isn't actually called yet - which is why the cell execution finishes very quickly.\n",
    "Instead, a *delayed object* is made, which keeps track of the function to call and the arguments to pass to it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d48ce9e-78a2-4e0a-96f7-0292377e15eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "delayed_square = dask.delayed(square)\n",
    "delayed_add = dask.delayed(add)\n",
    "delayed_square_root = dask.delayed(square_root)\n",
    "\n",
    "x = delayed_square(3)\n",
    "y = delayed_square(4)\n",
    "z = delayed_add(x, y)\n",
    "r = delayed_square_root(z)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3eab2c-83e8-42a9-8bea-57bfc9939f02",
   "metadata": {},
   "source": [
    "**This ran immediately, since nothing has really happened yet.** \n",
    "\n",
    "To get the result, call `compute`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b8a4af-2f6e-409d-b4e5-d2091dd9a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "r.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f3a89c-056f-4728-a149-5416bd5eb63d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"admonition alert alert-success\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\"></p>\n",
    "    Notice that this runs faster than the original code.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1e1b84-5c00-45f5-bd20-0bc1d4181d38",
   "metadata": {},
   "source": [
    "## What just happened?\n",
    "\n",
    "The `r` object is a lazy `Delayed` object.  This object holds everything we need to compute the final result, including references to all of the functions that are required and their inputs and relationship to one-another.  We can evaluate the result with `.compute()` as above or we can visualize the task graph for this value with `.visualize()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26843dd5-d964-4f4e-8833-642825a33f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7694b66e-acaa-4654-9c70-54f8244b5adc",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Reminder: Task and Task Graphs</p>\n",
    "    <ul>\n",
    "        <li> A task is a function that you want to call and its corresponding inputs. </li>\n",
    "    <li> A task graph is a collection of (1) the functions we want to call + their inputs (2) their dependencies. </li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "\n",
    "<img src=\"../images/dask-task-stream.gif\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "By default the task graph is rendered from top to bottom. In the case that you prefer to visualize it from left to right, pass `rankdir=\"LR\"` as a keyword argument to `.visualize()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b328fd0b-7ae0-4384-9425-56679142f837",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.visualize(rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6840ea39-1e37-4a8f-967e-e6fd88635c7e",
   "metadata": {},
   "source": [
    "Notice that this includes the names of the functions from before, and the logical flow of the outputs of the `square` functions to the inputs of `add` and `square_root`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ce789b-23d9-4c20-a029-c7daff778f19",
   "metadata": {},
   "source": [
    "### Some questions to consider:\n",
    "\n",
    "-  Why did we go from 4s to 3s?  Why weren't we able to parallelize down to 2s?\n",
    "-  What would have happened if the `square`, `add`, and `square_root` functions didn't include the `sleep(1)`?  Would Dask still be able to speed up this code?\n",
    "-  What if we have multiple outputs or also want to get access to x or y?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6c584c-22ab-4d55-a47e-3d3b7cc6cc91",
   "metadata": {},
   "source": [
    "## Exercise: Parallelize a for loop\n",
    "\n",
    "`for` loops are one of the most common things that we want to parallelize.  Use `dask.delayed` on our custom `square` function and the built-in `sum`  function to parallelize the computation below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4e55a0-2186-4c8e-af5e-347740deca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(range(1, 11))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123991ea-f457-4b9b-9dbb-b34a287b9165",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = []\n",
    "for x in data:\n",
    "    y = square(x)\n",
    "    results.append(y)\n",
    "\n",
    "total = sum(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f8e822-9f34-47fb-acb2-bec62ff8ec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ce1f45-c60a-42af-9c7a-d7594f0af72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Your parallel code here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba2b5cf-de53-4cfc-9852-efdd2f57ccbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Solution\n",
    "\n",
    "results = []\n",
    "\n",
    "for x in data:\n",
    "    y = delayed_square(x)\n",
    "    results.append(y)\n",
    "\n",
    "total = dask.delayed(sum)(results)\n",
    "print(f\"Before computing: {total}\")  # Let's see what type of thing total is\n",
    "\n",
    "result = total.compute()\n",
    "print(f\"After computing : {result}\", result)  # After it's computed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd43edf4-8e2e-40b6-ac29-d44515ea2f92",
   "metadata": {},
   "source": [
    "How do the graph visualizations compare with the given solution, compared to a version with the `sum` function used directly rather than wrapped with `delayed`? Can you explain the latter version? You might find the result of the following expression illuminating\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "delayed_square(1) + delayed_square(2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2020aa60-8ee4-490c-b89f-fd75839fc10a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z = delayed_square(1) + delayed_square(2)\n",
    "z.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3db9d1-3b59-4279-ae8e-84d56ad33db0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum(results).visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecc33e4-b6e9-4b41-88ac-46622a31ee37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cbebad-a393-4519-bae3-4e2ada490317",
   "metadata": {},
   "source": [
    "## Exercise: Parallelizing a for-loop code with control flow\n",
    "\n",
    "Often we want to delay only *some* functions, running a few of them immediately.  This is especially helpful when those functions are fast and help us to determine what other slower functions we should call.  This decision, to delay or not to delay, is usually where we need to be thoughtful when using `dask.delayed`.\n",
    "\n",
    "In the example below we iterate through a list of inputs.  If that input is even then we want to call `square`.  If the input is odd then we want to call `double`.  This `is_even` decision to call `square` or `double` has to be made immediately (not lazily) in order for our graph-building Python code to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e79c2d-1b4d-4686-9a77-f95195c73558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double(x):\n",
    "    time.sleep(1)\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "def square(x):\n",
    "    time.sleep(1)\n",
    "    return x ** 2\n",
    "\n",
    "\n",
    "def is_even(x):\n",
    "    return not x % 2\n",
    "\n",
    "\n",
    "data = list(range(1, 11))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ec334d-05ab-473c-9261-29e45aa32ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Sequential code\n",
    "\n",
    "results = []\n",
    "for x in data:\n",
    "    if is_even(x):\n",
    "        y = double(x)\n",
    "    else:\n",
    "        y = square(x)\n",
    "    results.append(y)\n",
    "\n",
    "total = sum(results)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396d290f-50df-41b1-bb70-49c54ccacd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Your parallel code here...\n",
    "# TODO: parallelize the sequential code above using dask.delayed\n",
    "# You will need to delay some functions, but not all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624a7474-911f-4e44-b490-5542597c50be",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for x in data:\n",
    "    if dask.delayed(is_even)(x):  # even\n",
    "        y = dask.delayed(double)(x)\n",
    "    else:  # odd\n",
    "        y = dask.delayed(square)(x)\n",
    "    results.append(y)\n",
    "\n",
    "total = dask.delayed(sum)(results)\n",
    "total.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9825ba4-6ba9-42b8-8823-d629b031c04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "total.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db442b4-c7d0-487e-8390-bf7b5e628b4a",
   "metadata": {},
   "source": [
    "### Some questions to consider:\n",
    "\n",
    "-  What are other examples of control flow where we can't use delayed?\n",
    "-  What would have happened if we had delayed the evaluation of `is_even(x)` in the example above?\n",
    "-  What are your thoughts on delaying `sum`?  This function is both computational but also fast to run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4397a5fc-8832-4aed-8b1a-1699374d95af",
   "metadata": {},
   "source": [
    "## Exercise: Parallelizing climatology and anomaly computations with xarray and `dask.delayed`\n",
    "\n",
    "In this exercise we read four netCDF files for 4 ensemble members of CESM2 output submitted to the CMIP6 project. We then use xarray to compute anomalies for each ensemble member in parallel i.e. compute the climatology and use xarray's groupby arithmetic to remove this climatology from our original data for each member. \n",
    "\n",
    "We are given sequential code to do this and parallelize it with `dask.delayed`.\n",
    "\n",
    "The computation we will parallelize is to compute the anomalies for each ensemble member from the input data.  We will do this by using `dask.delayed` together with `xarray`.  In a future section we will do this same exercise with xarray xarray dataset backed by `dask.array`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfe6378-2694-4c50-ba4e-bf80736de071",
   "metadata": {},
   "source": [
    "### Download data\n",
    "\n",
    "To download the necessary data, make sure to run the [Download Data Notebook](00-download-data.ipynb). This will download all necessary input files for four ensemble members (`r11i1p1f1`, `r7i1p1f1`, `r8i1p1f1`, `r9i1p1f1`) from the [esgf-node](https://esgf-node.llnl.gov/search/cmip6/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd94d30-b0f7-4e03-9e52-8986954b22bf",
   "metadata": {},
   "source": [
    "### Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed0d219-7971-47a0-994a-7f7d549d26a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "data_dir = pathlib.Path(\"data/\")\n",
    "files = sorted(data_dir.glob(\"tos_Omon_CESM2*\"))\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa14ba0-d208-43cb-b639-8cca2c57d979",
   "metadata": {},
   "source": [
    "### Read one file with `xarray.open_dataset` and compute anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28df05b-4003-40cc-92a0-d3d9981cbd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b76d08-97ff-46c1-9cf9-273f91f503ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(files[0], engine=\"netcdf4\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd054c3f-b748-4f7f-8cd3-c498b642819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute anomaly\n",
    "gb = ds.tos.groupby('time.month')\n",
    "tos_anom = gb - gb.mean(dim='time')\n",
    "tos_anom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3160be-4ffa-4344-a33a-2bcb4f451da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tos_anom.sel(lon=310, lat=50, method='nearest').plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5063d3-decf-4289-80ae-7f34b82d6526",
   "metadata": {},
   "source": [
    "### Sequential code: Anomaly for each ensemble member\n",
    "\n",
    "The above cell computes the anomaly for one ensemble member during the period spanning `2000 - 2014`. Here we expand that to all four ensemble members using a sequential for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f1d257-bfcd-4b6d-bb9f-85f6045ce008",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results = {}\n",
    "for file in files:\n",
    "\n",
    "    # Read in file\n",
    "    ds = xr.open_dataset(file, engine='netcdf4')\n",
    "\n",
    "    # Compute anomaly\n",
    "    gb = ds.tos.groupby('time.month')\n",
    "    tos_anom = gb - gb.mean(dim='time')\n",
    "\n",
    "    # Save the computed anomaly and record the name of the ensemble member\n",
    "    results[file.stem.split('_')[-3]] = tos_anom\n",
    "\n",
    "\n",
    "# Combine the results in our dataarray by concatenating the results across a new dimension `ensemble_member`\n",
    "dset_anom = xr.concat(list(results.values()), dim='ensemble_member')\n",
    "dset_anom['ensemble_member'] = list(results.keys())\n",
    "dset_anom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb12f72-1899-45fc-b198-8421318548ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_anom.sel(lon=310, lat=50, method='nearest').plot(col='ensemble_member', col_wrap=2, size=4);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d5a449-0b19-4181-82d1-8169268a5c87",
   "metadata": {},
   "source": [
    "### Parallelize the code above\n",
    "\n",
    "Use `dask.delayed` to parallelize the code above.  Some extra things you will need to know.\n",
    "\n",
    "1.  Methods and attribute access on delayed objects work automatically, so if you have a delayed object you can perform normal arithmetic, slicing, and method calls on it and it will produce the correct delayed calls.\n",
    "\n",
    "    ```python\n",
    "    ds = dask.delayed(xr.open_dataset)(files[0], engine='netcdf4')\n",
    "    ds.isel(time=0).sum() # everything here was delayed\n",
    "    ds.groupby('time.season').mean() # everything here was delayed\n",
    "    ```\n",
    "    \n",
    "2.  Calling the `.compute()` method works well when you have a single output.  When you have multiple outputs you might want to use the `dask.compute` function:\n",
    "\n",
    "    ```python\n",
    "    >>> from dask import delayed, compute\n",
    "    >>> x = delayed(np.arange)(10)\n",
    "    >>> y = x ** 2\n",
    "    >>> min_, max_ = compute(y.min(), y.max())\n",
    "    >>> min_, max_\n",
    "    (0, 81)\n",
    "    ```\n",
    "    \n",
    "    This way Dask can share the intermediate values (like `y = x**2`)\n",
    "    \n",
    "So your goal is to parallelize the code above (which has been copied below) using `dask.delayed`.  You may also want to visualize a bit of the computation to see if you're doing it correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52454acb-8c40-48b0-bbe1-b02a3372d293",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# This is just one possible solution, there are\n",
    "# several ways to do this using `delayed`\n",
    "\n",
    "results = {}\n",
    "for file in files:\n",
    "\n",
    "    # Read in file\n",
    "    ds = dask.delayed(xr.open_dataset)(file, engine='netcdf4')\n",
    "\n",
    "    # Compute anomaly\n",
    "    gb = ds.tos.groupby('time.month')\n",
    "    tos_anom = gb - gb.mean(dim='time')\n",
    "\n",
    "    # Save the computed anomaly and record the name of the ensemble member\n",
    "    results[file.stem.split('_')[-3]] = tos_anom\n",
    "\n",
    "\n",
    "# Compute the results\n",
    "# dask.compute() returns a tuple here with a single item. So, ensure to grab this one item by using the 0 index\n",
    "computed_results = dask.compute(results)[0]\n",
    "# Combine the results in our dataarray by concatenating the results across a new dimension `ensemble_member`\n",
    "dset_anom = xr.concat(list(computed_results.values()), dim='ensemble_member')\n",
    "dset_anom['ensemble_member'] = list(computed_results.keys())\n",
    "dset_anom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607452f5-9848-4b77-8755-6a36ab671c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a quick plot to ensure the results still match\n",
    "dset_anom.sel(lon=310, lat=50, method='nearest').plot(col='ensemble_member', col_wrap=2, size=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2a0fd1-03d4-4df7-8068-18e416a948a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc972e6-bb7a-4d9f-87db-285345756d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['r11i1p1f1'].visualize(rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899f93fa-ba7c-4818-895b-e7a214ce4593",
   "metadata": {},
   "source": [
    "### Some questions to consider:\n",
    "\n",
    "- How much speedup did you get? Is this how much speedup you'd expect?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaccf91-a83c-4a82-bee1-2950a461551c",
   "metadata": {},
   "source": [
    "## Close the Cluster and Client\n",
    "\n",
    "Before moving on to the next notebook, make sure to close your cluster, and client or stop this kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb5cd1b-a992-4d60-aa6a-5776dde37e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131dd25a-4d4e-4341-9340-1bed9a87b8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark --time --python --updated --iversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45775347-0f7e-4882-a5a2-4bc0ce60791a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be75c1e-84aa-49b6-a931-3649d4353cab",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- `dask.delayed` is a handy mechanism for creating the Dask graph, but the adventurous may wish to play with the full fexibility afforded by building the graph dictionaries directly. Detailed information can be found [here](https://dask.pydata.org/en/latest/graphs.html).\n",
    "\n",
    "## Learn More\n",
    "\n",
    "Visit the [Delayed documentation](https://docs.dask.org/en/latest/delayed.html). In particular, this [delayed screencast](https://www.youtube.com/watch?v=SHqFmynRxVU) will reinforce the concepts you learned here and the [delayed best practices](https://docs.dask.org/en/latest/delayed-best-practices.html) document collects advice on using `dask.delayed` well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2df68e-1b69-48f1-9f5d-11c238b812db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "YouTubeVideo(id=\"SHqFmynRxVU\", width=600, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238a4c70-964a-4667-b399-26e308ea4841",
   "metadata": {},
   "source": [
    "## Resources and references\n",
    "\n",
    "* Reference\n",
    "    *  [Docs](https://dask.org/)\n",
    "    *  [Examples](https://examples.dask.org/)\n",
    "    *  [Code](https://github.com/dask/dask/)\n",
    "    *  [Blog](https://blog.dask.org/)\n",
    "*  Ask for help\n",
    "    *   [`dask`](http://stackoverflow.com/questions/tagged/dask) tag on Stack Overflow, for usage questions\n",
    "    *   [github discussions](https://github.com/dask/dask/discussions) for general, non-bug, discussion, and usage questions\n",
    "    *   [github issues](https://github.com/dask/dask/issues/new) for bug reports and feature requests\n",
    "    \n",
    "* Pieces of this notebook are adapted from the following sources\n",
    "  * https://github.com/dask/dask-tutorial/blob/main/01_dask.delayed.ipynb\n",
    "  \n",
    "  \n",
    " <div class=\"admonition alert alert-success\">\n",
    "    <p class=\"title\" style=\"font-weight:bold\">Previous: <a href=\"./07-dask-intro.ipynb\">Introducing Dask</a></p>\n",
    "     <p class=\"title\" style=\"font-weight:bold\">Next: <a href=\"./09-dask-array.ipynb\">Dask Array</a></p>\n",
    "    \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
